---
permalink: /
title: "Haodong Duan 段浩东"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Haodong Duan is a postdoctoral researcher at [Shanghai AI Lab](https://www.shlab.org.cn), working on the evaluation of large language models and multi-modality models.
He received his Ph.D. degree from the [Multimedia Laboratory @ CUHK](https://mmlab.ie.cuhk.edu.hk) in 2023, supervised by Professor [Dahua Lin](http://dahua.site/).
During his Ph.D., he works on human-centric action understanding, including video classification, skeleton-based action recognition, pose estimation.
Before joining MMLAB, he received his B.S. degree in data science at Peking University in 2019. 
His research interests include video recognition, human-centric action understanding, and multi-modality learning. 
You can find his [CV](/files/resume_latest.pdf) here.

News
-----------------
- (2024.08) **[MMBench](https://mmbench.opencompass.org.cn/home)** is accepted by ECCV 2024 as oral presentation
- (2024.05) [MathBench](https://arxiv.org/abs/2405.12209) ![star](https://badgen.net/github/stars/open-compass/MathBench) is accepted by ACL 2024
- (2024.04) We released [MMStar](https://arxiv.org/abs/2403.20330) ![star](https://badgen.net/github/stars/MMStar-Benchmark/MMStar). In this work, we studied the vision-dispensable and data leakage problems in multi-modal evaluation
- (2024.03) Two papers ([BotChat](https://arxiv.org/abs/2310.13650) ![star](https://badgen.net/github/stars/open-compass/BotChat), [Ada-LEval](https://arxiv.org/abs/2404.06480) ![star](https://badgen.net/github/stars/open-compass/Ada-LEval)) are accepted by NAACL 2024
- (2023.12) We released **[VLMEvalKit](https://github.com/open-compass/VLMEvalKit)** ![star](https://badgen.net/github/stars/open-compass/VLMEvalKit) ![fork](https://badgen.net/github/forks/open-compass/VLMEvalKit), an all-in-one toolkit for evaluating LVLMs [[Report](https://arxiv.org/abs/2407.11691)] accepted by MM 2024
- (2023.10) [SkeleTR](https://arxiv.org/pdf/2309.11445.pdf) is accepted by ICCV 2023
- (2023.08) I received my Ph.D. degree from the [Multimedia Laboratory @ CUHK](https://mmlab.ie.cuhk.edu.hk) and joined the [Shanghai AI Lab](https://www.shlab.org.cn) as a postdoctoral researcher
- (2022.07) I started my internship at AWS AI, advised by [Dr. Mingze Xu](https://xumingze0308.github.io/)
- (2022.06) Give a talk at CVPR 2022 [OpenMMLab Tutorial](https://openmmlab.com/community/cvpr2022-tutorial) on human-centric action understanding [[Slides](/files/cvpr22_tutorial.pdf)]
- (2022.05) Release **[PYSKL](https://github.com/kennymckormick/pyskl)** ![star](https://badgen.net/github/stars/kennymckormick/pyskl) ![fork](https://badgen.net/github/forks/kennymckormick/pyskl), a codebase for skeleton action recognition [[Report](https://arxiv.org/abs/2205.09443)] accepted by MM 2022
- (2022.03) 3 papers are accepted by CVPR 2022 as Oral (**[PoseC3D](https://arxiv.org/abs/2104.13586)**, **[TransRank](https://arxiv.org/abs/2205.02028)**) or Poster ([OCSampler](https://arxiv.org/abs/2201.04388)) Presentation
- (2020.08) Join [OpenMMLab](https://openmmlab.com/) and serve as a maintainer of [**MMAction2**](https://github.com/open-mmlab/mmaction2) ![star](https://badgen.net/github/stars/open-mmlab/mmaction2) ![fork](https://badgen.net/github/forks/open-mmlab/mmaction2)
- (2020.07) [OmniSource](https://arxiv.org/abs/2003.13042) is accepted by ECCV 2020
- (2019.07) **[TRB](https://openaccess.thecvf.com/content_ICCV_2019/papers/Duan_TRB_A_Novel_Triplet_Representation_for_Understanding_2D_Human_Body_ICCV_2019_paper.pdf)** is accepted by ICCV 2019 as Oral Presentation

Professional Activities
----------------
- Conference Reviewer: ICCV[21-23], AAAI[22-24], CVPR[22-24], ECCV[22-24], NeurIPS[22-23], WACV23, ICLR23, EuroGraphics, etc.
- Journal Reviewer: TPAMI, IJCV, TIP, PR, TMM, etc.

<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5wygxlue8gu&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>