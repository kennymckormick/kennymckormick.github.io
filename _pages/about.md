---
permalink: /
title: "Haodong Duan 段浩东"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Haodong Duan is a postdoctoral researcher at [Shanghai AI Lab](https://www.shlab.org.cn), working on the evaluation of large language models and multi-modality models.
He received his Ph.D. degree from the [Multimedia Laboratory @ CUHK](https://mmlab.ie.cuhk.edu.hk) in 2023, supervised by Professor [Dahua Lin](http://dahua.site/).
During his Ph.D., he works on human-centric action understanding, including video classification, skeleton-based action recognition, pose estimation.
Before joining MMLAB, he received his B.S. degree in data science at Peking University in 2019. 
His research interests include video recognition, human-centric action understanding, and multi-modality learning. 
You can find his [CV](/files/resume_latest.pdf) here.

Our team is hiring full-time researchers / engineers and interns. If you are interested, don’t hesitate to contact duanhaodong@pjlab.org.cn. 

News
-----------------
- (2024.09) Three papers are accepted by NeurIPS 2024 main conference: [InternLM-XComposer2-4KHD](https://arxiv.org/abs/2404.06512) ![star](https://badgen.net/github/stars/InternLM/InternLM-XComposer), [MMStar](https://arxiv.org/abs/2403.20330) ![star](https://badgen.net/github/stars/MMStar-Benchmark/MMStar), [**Prism**](https://arxiv.org/abs/2406.14544) ![star](https://badgen.net/github/stars/SparksJoe/Prism). 
- (2024.09) Three papers are accepted by NeurIPS 2024 Dataset & Benchmark Track: [ShareGPT4Video](https://arxiv.org/abs/2406.04325v1) ![star](https://badgen.net/github/stars/ShareGPT4Omni/ShareGPT4Video), [GMAI-MMBench](https://arxiv.org/abs/2408.03361) ![star](https://badgen.net/github/stars/uni-medical/GMAI-MMBench), [MMBench-Video](https://arxiv.org/abs/2406.14515) ![star](https://badgen.net/github/stars/open-compass/VLMEvalKit). 
- (2024.08) **[MMBench](https://mmbench.opencompass.org.cn/home)** ![star](https://badgen.net/github/stars/open-compass/MMBench) is accepted by ECCV 2024 as oral presentation [Video](https://www.youtube.com/watch?v=9tMThEfzmjM)
- (2024.05) [MathBench](https://arxiv.org/abs/2405.12209) ![star](https://badgen.net/github/stars/open-compass/MathBench) is accepted by ACL 2024
- (2024.03) Two papers ([BotChat](https://arxiv.org/abs/2310.13650) ![star](https://badgen.net/github/stars/open-compass/BotChat), [Ada-LEval](https://arxiv.org/abs/2404.06480) ![star](https://badgen.net/github/stars/open-compass/Ada-LEval)) are accepted by NAACL 2024
- (2023.12) We released **[VLMEvalKit](https://github.com/open-compass/VLMEvalKit)** ![star](https://badgen.net/github/stars/open-compass/VLMEvalKit) ![fork](https://badgen.net/github/forks/open-compass/VLMEvalKit), an all-in-one toolkit for evaluating LVLMs [[Report](https://arxiv.org/abs/2407.11691)] accepted by MM 2024
- (2023.10) [SkeleTR](https://arxiv.org/pdf/2309.11445.pdf) is accepted by ICCV 2023
- (2023.08) I received my Ph.D. degree from the [Multimedia Laboratory @ CUHK](https://mmlab.ie.cuhk.edu.hk) and joined the [Shanghai AI Lab](https://www.shlab.org.cn) as a postdoctoral researcher
- (2022.07) I started my internship at AWS AI, advised by [Dr. Mingze Xu](https://xumingze0308.github.io/)
- (2022.06) Give a talk at CVPR 2022 [OpenMMLab Tutorial](https://openmmlab.com/community/cvpr2022-tutorial) on human-centric action understanding [[Slides](/files/cvpr22_tutorial.pdf)]
- (2022.05) Release **[PYSKL](https://github.com/kennymckormick/pyskl)** ![star](https://badgen.net/github/stars/kennymckormick/pyskl) ![fork](https://badgen.net/github/forks/kennymckormick/pyskl), a codebase for skeleton action recognition [[Report](https://arxiv.org/abs/2205.09443)] accepted by MM 2022
- (2022.03) Three papers are accepted by CVPR 2022 as Oral (**[PoseC3D](https://arxiv.org/abs/2104.13586)**, **[TransRank](https://arxiv.org/abs/2205.02028)**) or Poster ([OCSampler](https://arxiv.org/abs/2201.04388)) Presentation
- (2020.08) Join [OpenMMLab](https://openmmlab.com/) and serve as a maintainer of [**MMAction2**](https://github.com/open-mmlab/mmaction2) ![star](https://badgen.net/github/stars/open-mmlab/mmaction2) ![fork](https://badgen.net/github/forks/open-mmlab/mmaction2)
- (2020.07) [OmniSource](https://arxiv.org/abs/2003.13042) is accepted by ECCV 2020
- (2019.07) **[TRB](https://openaccess.thecvf.com/content_ICCV_2019/papers/Duan_TRB_A_Novel_Triplet_Representation_for_Understanding_2D_Human_Body_ICCV_2019_paper.pdf)** is accepted by ICCV 2019 as Oral Presentation

Professional Activities
----------------
- Conference Reviewer: ICCV[21-23], AAAI[22-25], CVPR[22-24], ECCV[22-24], NeurIPS[22-24], WACV23, ICML23, ICLR[23-24], EuroGraphics23, etc.
- Journal Reviewer: TPAMI, IJCV, TIP, PR, TMM, etc.

<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5wygxlue8gu&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>